{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.11","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":6116155,"sourceType":"datasetVersion","datasetId":2852448}],"dockerImageVersionId":31011,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nimport cv2\nimport tensorflow as tf\nlabels = []\nimgs = []\nfor dirname, _, filenames in os.walk('/kaggle/input/rgb-arabic-alphabets-sign-language-dataset/RGB ArSL dataset'):\n    for filename in filenames:\n        labels.append(dirname.split('/')[-1])\n        img = cv2.imread(os.path.join(dirname,filename))\n        img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n        img = cv2.resize(img,(224,224))\n        img = img /255.0\n        img= tf.convert_to_tensor(img,dtype=tf.float32)\n        imgs.append(img)\nimgs = tf.stack(imgs)\nlabels = np.array(labels)\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2025-05-08T18:06:09.436189Z","iopub.execute_input":"2025-05-08T18:06:09.436473Z","iopub.status.idle":"2025-05-08T18:12:02.969691Z","shell.execute_reply.started":"2025-05-08T18:06:09.436446Z","shell.execute_reply":"2025-05-08T18:12:02.968949Z"}},"outputs":[{"name":"stderr","text":"Premature end of JPEG file\n","output_type":"stream"}],"execution_count":8},{"cell_type":"code","source":"labels","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-08T18:12:02.970518Z","iopub.execute_input":"2025-05-08T18:12:02.970739Z","iopub.status.idle":"2025-05-08T18:12:02.976573Z","shell.execute_reply.started":"2025-05-08T18:12:02.970722Z","shell.execute_reply":"2025-05-08T18:12:02.975784Z"}},"outputs":[{"execution_count":9,"output_type":"execute_result","data":{"text/plain":"array(['Zain', 'Zain', 'Zain', ..., 'Laa', 'Laa', 'Laa'], dtype='<U11')"},"metadata":{}}],"execution_count":9},{"cell_type":"code","source":"from sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import LabelEncoder\nle = LabelEncoder()\nlabels = le.fit_transform(labels)\nX_train, X_test, y_train, y_test = train_test_split(\n    np.array(imgs), labels, test_size=0.2, random_state=42, shuffle=True\n)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-08T18:12:02.977260Z","iopub.execute_input":"2025-05-08T18:12:02.977562Z","iopub.status.idle":"2025-05-08T18:12:13.478966Z","shell.execute_reply.started":"2025-05-08T18:12:02.977538Z","shell.execute_reply":"2025-05-08T18:12:13.466679Z"}},"outputs":[],"execution_count":10},{"cell_type":"code","source":"from tensorflow.keras import layers, models\nfrom tensorflow.keras.applications import ResNet50\n\nbase_model = ResNet50(weights=\"imagenet\", include_top=False, input_shape=(224, 224, 3))\n\nbase_model.trainable = False\n\nmodel = models.Sequential([\n    base_model,\n    layers.GlobalAveragePooling2D(),\n    layers.Dense(128, activation='relu'),\n    layers.Dropout(0.2),\n    layers.Dense(31)\n])\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-08T18:12:13.479789Z","iopub.execute_input":"2025-05-08T18:12:13.480005Z","iopub.status.idle":"2025-05-08T18:12:14.931058Z","shell.execute_reply.started":"2025-05-08T18:12:13.479987Z","shell.execute_reply":"2025-05-08T18:12:14.930479Z"}},"outputs":[],"execution_count":11},{"cell_type":"code","source":"model.compile(\n    optimizer=tf.keras.optimizers.Adam(),\n    loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n    metrics=['accuracy']\n)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-08T18:12:14.932068Z","iopub.execute_input":"2025-05-08T18:12:14.932338Z","iopub.status.idle":"2025-05-08T18:12:14.940129Z","shell.execute_reply.started":"2025-05-08T18:12:14.932312Z","shell.execute_reply":"2025-05-08T18:12:14.939601Z"}},"outputs":[],"execution_count":12},{"cell_type":"code","source":"from tensorflow.keras.callbacks import EarlyStopping\nfrom PIL import Image, ImageFile\nImageFile.LOAD_TRUNCATED_IMAGES = True\nearly_stopping = EarlyStopping(\n    monitor='val_loss',   \n    patience=3,          \n    restore_best_weights=True \n)\n\nhistory = model.fit(\n    X_train,\n    y_train,\n    validation_data=(X_test,y_test),\n    epochs=10,\n    batch_size=64,\n    callbacks = [early_stopping]\n)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-08T18:12:14.940793Z","iopub.execute_input":"2025-05-08T18:12:14.940988Z","iopub.status.idle":"2025-05-08T18:16:16.328373Z","shell.execute_reply.started":"2025-05-08T18:12:14.940972Z","shell.execute_reply":"2025-05-08T18:16:16.327492Z"}},"outputs":[{"name":"stdout","text":"Epoch 1/10\n\u001b[1m99/99\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m43s\u001b[0m 308ms/step - accuracy: 0.0311 - loss: 3.4857 - val_accuracy: 0.0573 - val_loss: 3.4270\nEpoch 2/10\n\u001b[1m99/99\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 207ms/step - accuracy: 0.0454 - loss: 3.4288 - val_accuracy: 0.0573 - val_loss: 3.4163\nEpoch 3/10\n\u001b[1m99/99\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 218ms/step - accuracy: 0.0460 - loss: 3.4157 - val_accuracy: 0.0458 - val_loss: 3.4023\nEpoch 4/10\n\u001b[1m99/99\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 214ms/step - accuracy: 0.0496 - loss: 3.3965 - val_accuracy: 0.0681 - val_loss: 3.3781\nEpoch 5/10\n\u001b[1m99/99\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 209ms/step - accuracy: 0.0510 - loss: 3.3736 - val_accuracy: 0.0846 - val_loss: 3.3544\nEpoch 6/10\n\u001b[1m99/99\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 210ms/step - accuracy: 0.0614 - loss: 3.3571 - val_accuracy: 0.0763 - val_loss: 3.3332\nEpoch 7/10\n\u001b[1m99/99\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 212ms/step - accuracy: 0.0654 - loss: 3.3293 - val_accuracy: 0.0865 - val_loss: 3.3089\nEpoch 8/10\n\u001b[1m99/99\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 212ms/step - accuracy: 0.0616 - loss: 3.3139 - val_accuracy: 0.0782 - val_loss: 3.2974\nEpoch 9/10\n\u001b[1m99/99\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 211ms/step - accuracy: 0.0642 - loss: 3.2978 - val_accuracy: 0.0833 - val_loss: 3.2743\nEpoch 10/10\n\u001b[1m99/99\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 210ms/step - accuracy: 0.0734 - loss: 3.2767 - val_accuracy: 0.0700 - val_loss: 3.2917\n","output_type":"stream"}],"execution_count":13},{"cell_type":"code","source":"history = model.fit(\n    X_train,\n    y_train,\n    validation_data=(X_test,y_test),\n    epochs=300,\n    batch_size=128,\n    callbacks = [early_stopping]\n)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-08T18:16:16.329602Z","iopub.execute_input":"2025-05-08T18:16:16.329880Z","iopub.status.idle":"2025-05-08T18:37:50.424080Z","shell.execute_reply.started":"2025-05-08T18:16:16.329852Z","shell.execute_reply":"2025-05-08T18:37:50.423346Z"}},"outputs":[{"name":"stdout","text":"Epoch 1/300\n\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 488ms/step - accuracy: 0.0667 - loss: 3.2988 - val_accuracy: 0.0827 - val_loss: 3.2749\nEpoch 2/300\n\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 437ms/step - accuracy: 0.0645 - loss: 3.2772 - val_accuracy: 0.0814 - val_loss: 3.2665\nEpoch 3/300\n\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 418ms/step - accuracy: 0.0705 - loss: 3.2810 - val_accuracy: 0.0884 - val_loss: 3.2554\nEpoch 4/300\n\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 406ms/step - accuracy: 0.0634 - loss: 3.2877 - val_accuracy: 0.0846 - val_loss: 3.2539\nEpoch 5/300\n\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 408ms/step - accuracy: 0.0729 - loss: 3.2649 - val_accuracy: 0.0840 - val_loss: 3.2481\nEpoch 6/300\n\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 416ms/step - accuracy: 0.0700 - loss: 3.2602 - val_accuracy: 0.0833 - val_loss: 3.2434\nEpoch 7/300\n\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 416ms/step - accuracy: 0.0726 - loss: 3.2621 - val_accuracy: 0.0821 - val_loss: 3.2404\nEpoch 8/300\n\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 410ms/step - accuracy: 0.0664 - loss: 3.2567 - val_accuracy: 0.0852 - val_loss: 3.2364\nEpoch 9/300\n\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 409ms/step - accuracy: 0.0653 - loss: 3.2553 - val_accuracy: 0.0840 - val_loss: 3.2347\nEpoch 10/300\n\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 412ms/step - accuracy: 0.0678 - loss: 3.2569 - val_accuracy: 0.0872 - val_loss: 3.2293\nEpoch 11/300\n\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 414ms/step - accuracy: 0.0717 - loss: 3.2505 - val_accuracy: 0.0865 - val_loss: 3.2221\nEpoch 12/300\n\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 410ms/step - accuracy: 0.0607 - loss: 3.2503 - val_accuracy: 0.0852 - val_loss: 3.2228\nEpoch 13/300\n\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 409ms/step - accuracy: 0.0691 - loss: 3.2439 - val_accuracy: 0.0814 - val_loss: 3.2283\nEpoch 14/300\n\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 411ms/step - accuracy: 0.0791 - loss: 3.2397 - val_accuracy: 0.0814 - val_loss: 3.2180\nEpoch 15/300\n\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 409ms/step - accuracy: 0.0748 - loss: 3.2339 - val_accuracy: 0.0872 - val_loss: 3.2137\nEpoch 16/300\n\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 410ms/step - accuracy: 0.0693 - loss: 3.2379 - val_accuracy: 0.0865 - val_loss: 3.2135\nEpoch 17/300\n\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 410ms/step - accuracy: 0.0746 - loss: 3.2402 - val_accuracy: 0.0910 - val_loss: 3.2065\nEpoch 18/300\n\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 407ms/step - accuracy: 0.0686 - loss: 3.2364 - val_accuracy: 0.0922 - val_loss: 3.2074\nEpoch 19/300\n\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 409ms/step - accuracy: 0.0745 - loss: 3.2187 - val_accuracy: 0.0903 - val_loss: 3.2089\nEpoch 20/300\n\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 412ms/step - accuracy: 0.0721 - loss: 3.2226 - val_accuracy: 0.0827 - val_loss: 3.1954\nEpoch 21/300\n\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 412ms/step - accuracy: 0.0775 - loss: 3.2221 - val_accuracy: 0.0903 - val_loss: 3.1950\nEpoch 22/300\n\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 410ms/step - accuracy: 0.0756 - loss: 3.2190 - val_accuracy: 0.0865 - val_loss: 3.1957\nEpoch 23/300\n\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 412ms/step - accuracy: 0.0677 - loss: 3.2208 - val_accuracy: 0.0878 - val_loss: 3.1913\nEpoch 24/300\n\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 413ms/step - accuracy: 0.0706 - loss: 3.2137 - val_accuracy: 0.0929 - val_loss: 3.1885\nEpoch 25/300\n\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 413ms/step - accuracy: 0.0704 - loss: 3.2230 - val_accuracy: 0.0916 - val_loss: 3.1844\nEpoch 26/300\n\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 410ms/step - accuracy: 0.0753 - loss: 3.2054 - val_accuracy: 0.0903 - val_loss: 3.1847\nEpoch 27/300\n\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 410ms/step - accuracy: 0.0832 - loss: 3.2078 - val_accuracy: 0.0910 - val_loss: 3.1874\nEpoch 28/300\n\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 414ms/step - accuracy: 0.0776 - loss: 3.1988 - val_accuracy: 0.0872 - val_loss: 3.1737\nEpoch 29/300\n\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 410ms/step - accuracy: 0.0849 - loss: 3.1998 - val_accuracy: 0.0948 - val_loss: 3.1741\nEpoch 30/300\n\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 414ms/step - accuracy: 0.0755 - loss: 3.2080 - val_accuracy: 0.0935 - val_loss: 3.1733\nEpoch 31/300\n\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 411ms/step - accuracy: 0.0741 - loss: 3.1991 - val_accuracy: 0.0922 - val_loss: 3.1735\nEpoch 32/300\n\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 412ms/step - accuracy: 0.0710 - loss: 3.1867 - val_accuracy: 0.0910 - val_loss: 3.1690\nEpoch 33/300\n\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 410ms/step - accuracy: 0.0760 - loss: 3.1960 - val_accuracy: 0.0852 - val_loss: 3.1624\nEpoch 34/300\n\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 408ms/step - accuracy: 0.0795 - loss: 3.1896 - val_accuracy: 0.0999 - val_loss: 3.1667\nEpoch 35/300\n\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 407ms/step - accuracy: 0.0737 - loss: 3.1888 - val_accuracy: 0.0859 - val_loss: 3.1728\nEpoch 36/300\n\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 413ms/step - accuracy: 0.0842 - loss: 3.1814 - val_accuracy: 0.0961 - val_loss: 3.1577\nEpoch 37/300\n\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 412ms/step - accuracy: 0.0731 - loss: 3.1889 - val_accuracy: 0.0992 - val_loss: 3.1560\nEpoch 38/300\n\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 411ms/step - accuracy: 0.0771 - loss: 3.1935 - val_accuracy: 0.0954 - val_loss: 3.1570\nEpoch 39/300\n\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 413ms/step - accuracy: 0.0876 - loss: 3.1692 - val_accuracy: 0.0967 - val_loss: 3.1528\nEpoch 40/300\n\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 412ms/step - accuracy: 0.0752 - loss: 3.1728 - val_accuracy: 0.0961 - val_loss: 3.1514\nEpoch 41/300\n\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 412ms/step - accuracy: 0.0824 - loss: 3.1784 - val_accuracy: 0.0948 - val_loss: 3.1471\nEpoch 42/300\n\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 411ms/step - accuracy: 0.0790 - loss: 3.1781 - val_accuracy: 0.0986 - val_loss: 3.1491\nEpoch 43/300\n\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 412ms/step - accuracy: 0.0818 - loss: 3.1732 - val_accuracy: 0.0973 - val_loss: 3.1466\nEpoch 44/300\n\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 411ms/step - accuracy: 0.0804 - loss: 3.1819 - val_accuracy: 0.0948 - val_loss: 3.1420\nEpoch 45/300\n\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 412ms/step - accuracy: 0.0812 - loss: 3.1737 - val_accuracy: 0.0999 - val_loss: 3.1378\nEpoch 46/300\n\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 409ms/step - accuracy: 0.0794 - loss: 3.1734 - val_accuracy: 0.0967 - val_loss: 3.1388\nEpoch 47/300\n\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 412ms/step - accuracy: 0.0775 - loss: 3.1741 - val_accuracy: 0.0954 - val_loss: 3.1328\nEpoch 48/300\n\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 412ms/step - accuracy: 0.0820 - loss: 3.1807 - val_accuracy: 0.0967 - val_loss: 3.1339\nEpoch 49/300\n\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 409ms/step - accuracy: 0.0755 - loss: 3.1706 - val_accuracy: 0.0973 - val_loss: 3.1363\nEpoch 50/300\n\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 413ms/step - accuracy: 0.0893 - loss: 3.1598 - val_accuracy: 0.0948 - val_loss: 3.1284\nEpoch 51/300\n\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 410ms/step - accuracy: 0.0836 - loss: 3.1578 - val_accuracy: 0.0878 - val_loss: 3.1429\nEpoch 52/300\n\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 414ms/step - accuracy: 0.0807 - loss: 3.1649 - val_accuracy: 0.0929 - val_loss: 3.1191\nEpoch 53/300\n\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 410ms/step - accuracy: 0.0812 - loss: 3.1726 - val_accuracy: 0.0954 - val_loss: 3.1287\nEpoch 54/300\n\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 408ms/step - accuracy: 0.0783 - loss: 3.1531 - val_accuracy: 0.0992 - val_loss: 3.1217\nEpoch 55/300\n\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 412ms/step - accuracy: 0.0883 - loss: 3.1548 - val_accuracy: 0.0941 - val_loss: 3.1178\nEpoch 56/300\n\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 409ms/step - accuracy: 0.0793 - loss: 3.1670 - val_accuracy: 0.0948 - val_loss: 3.1292\nEpoch 57/300\n\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 413ms/step - accuracy: 0.0892 - loss: 3.1635 - val_accuracy: 0.0973 - val_loss: 3.1134\nEpoch 58/300\n\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 411ms/step - accuracy: 0.0876 - loss: 3.1516 - val_accuracy: 0.0903 - val_loss: 3.1228\nEpoch 59/300\n\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 413ms/step - accuracy: 0.0853 - loss: 3.1340 - val_accuracy: 0.0910 - val_loss: 3.1105\nEpoch 60/300\n\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 410ms/step - accuracy: 0.0802 - loss: 3.1556 - val_accuracy: 0.0922 - val_loss: 3.1251\nEpoch 61/300\n\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 409ms/step - accuracy: 0.0799 - loss: 3.1588 - val_accuracy: 0.0941 - val_loss: 3.1126\nEpoch 62/300\n\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 410ms/step - accuracy: 0.0975 - loss: 3.1306 - val_accuracy: 0.1031 - val_loss: 3.1125\n","output_type":"stream"}],"execution_count":14},{"cell_type":"code","source":"history2 = model.fit(\n    X_train,\n    y_train,\n    validation_data=(X_test,y_test),\n    epochs=300,\n    batch_size=128\n)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"from tensorflow.keras import layers, models\nimport tensorflow.keras.applications\n\nbase_model = tf.keras.applications.EfficientNetB0(\n    include_top=False,\n    input_shape=(224,224,3),\n    classes=31,\n    classifier_activation='softmax',\n)\neff_model = models.Sequential([\n    base_model,\n    layers.GlobalAveragePooling2D(),\n    layers.Dense(128, activation='relu'),\n    layers.Dropout(0.2),\n    layers.Dense(31)\n])\n\neff_model.compile(\n    optimizer=tf.keras.optimizers.Adam(),\n    loss='sparse_categorical_crossentropy',\n    metrics=['accuracy']\n)\nhistory_eff = eff_model.fit(    X_train,\n    y_train,\n    validation_data=(X_test,y_test),\n    epochs=300,\n    batch_size=64)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-08T18:47:31.552572Z","iopub.execute_input":"2025-05-08T18:47:31.552883Z","iopub.status.idle":"2025-05-08T19:53:51.053726Z","shell.execute_reply.started":"2025-05-08T18:47:31.552860Z","shell.execute_reply":"2025-05-08T19:53:51.052465Z"}},"outputs":[{"name":"stdout","text":"Epoch 1/300\n","output_type":"stream"},{"name":"stderr","text":"E0000 00:00:1746730135.197757    5941 gpu_timer.cc:82] Delay kernel timed out: measured time has sub-optimal accuracy. There may be a missing warmup execution, please investigate in Nsight Systems.\nE0000 00:00:1746730135.356253    5941 gpu_timer.cc:82] Delay kernel timed out: measured time has sub-optimal accuracy. There may be a missing warmup execution, please investigate in Nsight Systems.\nE0000 00:00:1746730136.016472    5941 gpu_timer.cc:82] Delay kernel timed out: measured time has sub-optimal accuracy. There may be a missing warmup execution, please investigate in Nsight Systems.\nE0000 00:00:1746730136.158813    5941 gpu_timer.cc:82] Delay kernel timed out: measured time has sub-optimal accuracy. There may be a missing warmup execution, please investigate in Nsight Systems.\nE0000 00:00:1746730136.621732    5941 gpu_timer.cc:82] Delay kernel timed out: measured time has sub-optimal accuracy. There may be a missing warmup execution, please investigate in Nsight Systems.\nE0000 00:00:1746730136.766344    5941 gpu_timer.cc:82] Delay kernel timed out: measured time has sub-optimal accuracy. There may be a missing warmup execution, please investigate in Nsight Systems.\n","output_type":"stream"},{"name":"stdout","text":"\u001b[1m98/99\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 254ms/step - accuracy: 0.1119 - loss: 7.7599","output_type":"stream"},{"name":"stderr","text":"E0000 00:00:1746730195.253879    5941 gpu_timer.cc:82] Delay kernel timed out: measured time has sub-optimal accuracy. There may be a missing warmup execution, please investigate in Nsight Systems.\nE0000 00:00:1746730195.391610    5941 gpu_timer.cc:82] Delay kernel timed out: measured time has sub-optimal accuracy. There may be a missing warmup execution, please investigate in Nsight Systems.\n","output_type":"stream"},{"name":"stdout","text":"\u001b[1m99/99\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m171s\u001b[0m 745ms/step - accuracy: 0.1127 - loss: 7.7289 - val_accuracy: 0.0344 - val_loss: 12.7860\nEpoch 2/300\n\u001b[1m99/99\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 274ms/step - accuracy: 0.3115 - loss: 3.7862 - val_accuracy: 0.0344 - val_loss: 14.1246\nEpoch 3/300\n\u001b[1m99/99\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 265ms/step - accuracy: 0.3052 - loss: 4.0444 - val_accuracy: 0.0121 - val_loss: 3.4578\nEpoch 4/300\n\u001b[1m99/99\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 257ms/step - accuracy: 0.0844 - loss: 7.3891 - val_accuracy: 0.0331 - val_loss: 14.0836\nEpoch 5/300\n\u001b[1m99/99\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 252ms/step - accuracy: 0.0315 - loss: 3.4959 - val_accuracy: 0.0413 - val_loss: 14.7362\nEpoch 6/300\n\u001b[1m99/99\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 251ms/step - accuracy: 0.0338 - loss: 3.4639 - val_accuracy: 0.0407 - val_loss: 8.6129\nEpoch 7/300\n\u001b[1m99/99\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 251ms/step - accuracy: 0.0324 - loss: 3.4406 - val_accuracy: 0.0401 - val_loss: 3.4520\nEpoch 8/300\n\u001b[1m99/99\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 249ms/step - accuracy: 0.0343 - loss: 3.4432 - val_accuracy: 0.0522 - val_loss: 3.4340\nEpoch 9/300\n\u001b[1m99/99\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 249ms/step - accuracy: 0.0433 - loss: 3.4384 - val_accuracy: 0.0483 - val_loss: 3.4340\nEpoch 10/300\n\u001b[1m99/99\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 250ms/step - accuracy: 0.0439 - loss: 3.4352 - val_accuracy: 0.0363 - val_loss: 3.4340\nEpoch 11/300\n\u001b[1m99/99\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 249ms/step - accuracy: 0.0347 - loss: 3.4340 - val_accuracy: 0.0331 - val_loss: 3.4340\nEpoch 12/300\n\u001b[1m99/99\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 249ms/step - accuracy: 0.0310 - loss: 3.4350 - val_accuracy: 0.0312 - val_loss: 3.4340\nEpoch 13/300\n\u001b[1m99/99\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 249ms/step - accuracy: 0.0331 - loss: 3.4358 - val_accuracy: 0.0318 - val_loss: 3.4340\nEpoch 14/300\n\u001b[1m99/99\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 249ms/step - accuracy: 0.0328 - loss: 3.4351 - val_accuracy: 0.0254 - val_loss: 3.4340\nEpoch 15/300\n\u001b[1m99/99\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 249ms/step - accuracy: 0.0394 - loss: 3.4360 - val_accuracy: 0.0267 - val_loss: 3.4340\nEpoch 16/300\n\u001b[1m99/99\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 249ms/step - accuracy: 0.0377 - loss: 3.4379 - val_accuracy: 0.0229 - val_loss: 3.4340\nEpoch 17/300\n\u001b[1m99/99\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 249ms/step - accuracy: 0.0312 - loss: 3.4333 - val_accuracy: 0.0229 - val_loss: 3.4340\nEpoch 18/300\n\u001b[1m99/99\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 249ms/step - accuracy: 0.0355 - loss: 3.4340 - val_accuracy: 0.0235 - val_loss: 3.4340\nEpoch 19/300\n\u001b[1m99/99\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 249ms/step - accuracy: 0.0303 - loss: 3.4340 - val_accuracy: 0.0229 - val_loss: 3.4340\nEpoch 20/300\n\u001b[1m99/99\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 249ms/step - accuracy: 0.0334 - loss: 3.4340 - val_accuracy: 0.0229 - val_loss: 3.4340\nEpoch 21/300\n\u001b[1m99/99\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 249ms/step - accuracy: 0.0323 - loss: 3.4355 - val_accuracy: 0.0223 - val_loss: 3.4340\nEpoch 22/300\n\u001b[1m99/99\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 249ms/step - accuracy: 0.0316 - loss: 3.4380 - val_accuracy: 0.0223 - val_loss: 3.4340\nEpoch 23/300\n\u001b[1m99/99\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 249ms/step - accuracy: 0.0321 - loss: 3.4355 - val_accuracy: 0.0210 - val_loss: 3.4340\nEpoch 24/300\n\u001b[1m99/99\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 249ms/step - accuracy: 0.0350 - loss: 3.4350 - val_accuracy: 0.0267 - val_loss: 3.4340\nEpoch 25/300\n\u001b[1m99/99\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 249ms/step - accuracy: 0.0365 - loss: 3.4348 - val_accuracy: 0.0274 - val_loss: 3.4340\nEpoch 26/300\n\u001b[1m99/99\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 249ms/step - accuracy: 0.0347 - loss: 3.4340 - val_accuracy: 0.0286 - val_loss: 3.4340\nEpoch 27/300\n\u001b[1m99/99\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 248ms/step - accuracy: 0.0356 - loss: 3.4340 - val_accuracy: 0.0280 - val_loss: 3.4340\nEpoch 28/300\n\u001b[1m99/99\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 248ms/step - accuracy: 0.0337 - loss: 3.4340 - val_accuracy: 0.0286 - val_loss: 3.4340\nEpoch 29/300\n\u001b[1m99/99\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 248ms/step - accuracy: 0.0366 - loss: 3.4340 - val_accuracy: 0.0274 - val_loss: 3.4340\nEpoch 30/300\n\u001b[1m99/99\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 249ms/step - accuracy: 0.0377 - loss: 3.4362 - val_accuracy: 0.0274 - val_loss: 3.4340\nEpoch 31/300\n\u001b[1m99/99\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 249ms/step - accuracy: 0.0366 - loss: 3.4340 - val_accuracy: 0.0280 - val_loss: 3.4340\nEpoch 32/300\n\u001b[1m99/99\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 250ms/step - accuracy: 0.0349 - loss: 3.4363 - val_accuracy: 0.0350 - val_loss: 3.4340\nEpoch 33/300\n\u001b[1m99/99\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 249ms/step - accuracy: 0.0344 - loss: 3.4386 - val_accuracy: 0.0318 - val_loss: 3.4340\nEpoch 34/300\n\u001b[1m99/99\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 250ms/step - accuracy: 0.0350 - loss: 3.4368 - val_accuracy: 0.0356 - val_loss: 3.4340\nEpoch 35/300\n\u001b[1m99/99\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 249ms/step - accuracy: 0.0391 - loss: 3.4358 - val_accuracy: 0.0394 - val_loss: 3.4340\nEpoch 36/300\n\u001b[1m99/99\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 249ms/step - accuracy: 0.0405 - loss: 3.4371 - val_accuracy: 0.0363 - val_loss: 3.4340\nEpoch 37/300\n\u001b[1m99/99\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 250ms/step - accuracy: 0.0394 - loss: 3.4387 - val_accuracy: 0.0312 - val_loss: 3.4340\nEpoch 38/300\n\u001b[1m99/99\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 250ms/step - accuracy: 0.0349 - loss: 3.4429 - val_accuracy: 0.0337 - val_loss: 3.4340\nEpoch 39/300\n\u001b[1m99/99\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 249ms/step - accuracy: 0.0328 - loss: 3.4340 - val_accuracy: 0.0350 - val_loss: 3.4340\nEpoch 40/300\n\u001b[1m99/99\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 251ms/step - accuracy: 0.0304 - loss: 3.4408 - val_accuracy: 0.0369 - val_loss: 3.4340\nEpoch 41/300\n\u001b[1m99/99\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 249ms/step - accuracy: 0.0280 - loss: 3.4383 - val_accuracy: 0.0299 - val_loss: 3.4340\nEpoch 42/300\n\u001b[1m99/99\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 249ms/step - accuracy: 0.0273 - loss: 3.4381 - val_accuracy: 0.0337 - val_loss: 3.4340\nEpoch 43/300\n\u001b[1m99/99\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 249ms/step - accuracy: 0.0264 - loss: 3.4359 - val_accuracy: 0.0286 - val_loss: 3.4340\nEpoch 44/300\n\u001b[1m99/99\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 249ms/step - accuracy: 0.0289 - loss: 3.4340 - val_accuracy: 0.0286 - val_loss: 3.4340\nEpoch 45/300\n\u001b[1m99/99\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 250ms/step - accuracy: 0.0291 - loss: 3.4370 - val_accuracy: 0.0382 - val_loss: 3.4340\nEpoch 46/300\n\u001b[1m99/99\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 248ms/step - accuracy: 0.0289 - loss: 3.4340 - val_accuracy: 0.0394 - val_loss: 3.4340\nEpoch 47/300\n\u001b[1m99/99\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 249ms/step - accuracy: 0.0313 - loss: 3.4348 - val_accuracy: 0.0407 - val_loss: 3.4340\nEpoch 48/300\n\u001b[1m99/99\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 249ms/step - accuracy: 0.0295 - loss: 3.4367 - val_accuracy: 0.0407 - val_loss: 3.4340\nEpoch 49/300\n\u001b[1m99/99\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 249ms/step - accuracy: 0.0320 - loss: 3.4340 - val_accuracy: 0.0420 - val_loss: 3.4340\nEpoch 50/300\n\u001b[1m99/99\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 249ms/step - accuracy: 0.0337 - loss: 3.4340 - val_accuracy: 0.0413 - val_loss: 3.4340\nEpoch 51/300\n\u001b[1m99/99\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 249ms/step - accuracy: 0.0307 - loss: 3.4340 - val_accuracy: 0.0407 - val_loss: 3.4340\nEpoch 52/300\n\u001b[1m99/99\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 250ms/step - accuracy: 0.0310 - loss: 3.4340 - val_accuracy: 0.0407 - val_loss: 3.4340\nEpoch 53/300\n\u001b[1m99/99\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 249ms/step - accuracy: 0.0315 - loss: 3.4340 - val_accuracy: 0.0413 - val_loss: 3.4340\nEpoch 54/300\n\u001b[1m99/99\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 250ms/step - accuracy: 0.0319 - loss: 3.4340 - val_accuracy: 0.0413 - val_loss: 3.4340\nEpoch 55/300\n\u001b[1m99/99\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 249ms/step - accuracy: 0.0319 - loss: 3.4340 - val_accuracy: 0.0413 - val_loss: 3.4340\nEpoch 56/300\n\u001b[1m99/99\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 248ms/step - accuracy: 0.0289 - loss: 3.4340 - val_accuracy: 0.0413 - val_loss: 3.4340\nEpoch 57/300\n\u001b[1m99/99\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 249ms/step - accuracy: 0.0284 - loss: 3.4340 - val_accuracy: 0.0407 - val_loss: 3.4340\nEpoch 58/300\n\u001b[1m99/99\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 249ms/step - accuracy: 0.0325 - loss: 3.4340 - val_accuracy: 0.0413 - val_loss: 3.4340\nEpoch 59/300\n\u001b[1m99/99\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 248ms/step - accuracy: 0.0332 - loss: 3.4340 - val_accuracy: 0.0413 - val_loss: 3.4340\nEpoch 60/300\n\u001b[1m99/99\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 248ms/step - accuracy: 0.0324 - loss: 3.4340 - val_accuracy: 0.0413 - val_loss: 3.4340\nEpoch 61/300\n\u001b[1m99/99\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 249ms/step - accuracy: 0.0311 - loss: 3.4340 - val_accuracy: 0.0413 - val_loss: 3.4340\nEpoch 62/300\n\u001b[1m99/99\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 248ms/step - accuracy: 0.0306 - loss: 3.4340 - val_accuracy: 0.0413 - val_loss: 3.4340\nEpoch 63/300\n\u001b[1m99/99\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 248ms/step - accuracy: 0.0365 - loss: 3.4340 - val_accuracy: 0.0413 - val_loss: 3.4340\nEpoch 64/300\n\u001b[1m99/99\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 249ms/step - accuracy: 0.0327 - loss: 3.4369 - val_accuracy: 0.0464 - val_loss: 3.4340\nEpoch 65/300\n\u001b[1m99/99\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 249ms/step - accuracy: 0.0314 - loss: 3.4340 - val_accuracy: 0.0452 - val_loss: 3.4340\nEpoch 66/300\n\u001b[1m99/99\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 249ms/step - accuracy: 0.0320 - loss: 3.4340 - val_accuracy: 0.0439 - val_loss: 3.4340\nEpoch 67/300\n\u001b[1m99/99\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 249ms/step - accuracy: 0.0362 - loss: 3.4340 - val_accuracy: 0.0439 - val_loss: 3.4340\nEpoch 68/300\n\u001b[1m99/99\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 248ms/step - accuracy: 0.0344 - loss: 3.4340 - val_accuracy: 0.0439 - val_loss: 3.4340\nEpoch 69/300\n\u001b[1m99/99\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 249ms/step - accuracy: 0.0293 - loss: 3.4340 - val_accuracy: 0.0439 - val_loss: 3.4340\nEpoch 70/300\n\u001b[1m99/99\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 249ms/step - accuracy: 0.0279 - loss: 3.4359 - val_accuracy: 0.0388 - val_loss: 3.4340\nEpoch 71/300\n\u001b[1m99/99\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 248ms/step - accuracy: 0.0299 - loss: 3.4340 - val_accuracy: 0.0350 - val_loss: 3.4340\nEpoch 72/300\n\u001b[1m99/99\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 249ms/step - accuracy: 0.0310 - loss: 3.4340 - val_accuracy: 0.0356 - val_loss: 3.4340\nEpoch 73/300\n\u001b[1m99/99\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 249ms/step - accuracy: 0.0286 - loss: 3.4340 - val_accuracy: 0.0363 - val_loss: 3.4340\nEpoch 74/300\n\u001b[1m99/99\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 248ms/step - accuracy: 0.0323 - loss: 3.4340 - val_accuracy: 0.0356 - val_loss: 3.4340\nEpoch 75/300\n\u001b[1m99/99\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 249ms/step - accuracy: 0.0327 - loss: 3.4340 - val_accuracy: 0.0369 - val_loss: 3.4340\nEpoch 76/300\n\u001b[1m99/99\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 249ms/step - accuracy: 0.0296 - loss: 3.4340 - val_accuracy: 0.0363 - val_loss: 3.4340\nEpoch 77/300\n\u001b[1m99/99\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 249ms/step - accuracy: 0.0305 - loss: 3.4340 - val_accuracy: 0.0363 - val_loss: 3.4340\nEpoch 78/300\n\u001b[1m99/99\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 249ms/step - accuracy: 0.0357 - loss: 3.4340 - val_accuracy: 0.0356 - val_loss: 3.4340\nEpoch 79/300\n\u001b[1m99/99\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 249ms/step - accuracy: 0.0328 - loss: 3.4340 - val_accuracy: 0.0356 - val_loss: 3.4340\nEpoch 80/300\n\u001b[1m99/99\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 248ms/step - accuracy: 0.0303 - loss: 3.4340 - val_accuracy: 0.0350 - val_loss: 3.4340\nEpoch 81/300\n\u001b[1m99/99\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 249ms/step - accuracy: 0.0287 - loss: 3.4351 - val_accuracy: 0.0382 - val_loss: 3.4340\nEpoch 82/300\n\u001b[1m99/99\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 249ms/step - accuracy: 0.0309 - loss: 3.4340 - val_accuracy: 0.0382 - val_loss: 3.4340\nEpoch 83/300\n\u001b[1m99/99\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 249ms/step - accuracy: 0.0280 - loss: 3.4340 - val_accuracy: 0.0401 - val_loss: 3.4340\nEpoch 84/300\n\u001b[1m99/99\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 248ms/step - accuracy: 0.0326 - loss: 3.4340 - val_accuracy: 0.0401 - val_loss: 3.4340\nEpoch 85/300\n\u001b[1m99/99\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 248ms/step - accuracy: 0.0323 - loss: 3.4343 - val_accuracy: 0.0394 - val_loss: 3.4340\nEpoch 86/300\n\u001b[1m99/99\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 248ms/step - accuracy: 0.0319 - loss: 3.4340 - val_accuracy: 0.0375 - val_loss: 3.4340\nEpoch 87/300\n\u001b[1m99/99\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 249ms/step - accuracy: 0.0332 - loss: 3.4340 - val_accuracy: 0.0375 - val_loss: 3.4340\nEpoch 88/300\n\u001b[1m99/99\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 248ms/step - accuracy: 0.0268 - loss: 3.4340 - val_accuracy: 0.0375 - val_loss: 3.4340\nEpoch 89/300\n\u001b[1m99/99\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 249ms/step - accuracy: 0.0278 - loss: 3.4340 - val_accuracy: 0.0375 - val_loss: 3.4340\nEpoch 90/300\n\u001b[1m99/99\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 249ms/step - accuracy: 0.0335 - loss: 3.4340 - val_accuracy: 0.0375 - val_loss: 3.4340\nEpoch 91/300\n\u001b[1m99/99\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 249ms/step - accuracy: 0.0370 - loss: 3.4340 - val_accuracy: 0.0375 - val_loss: 3.4340\nEpoch 92/300\n\u001b[1m99/99\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 249ms/step - accuracy: 0.0312 - loss: 3.4340 - val_accuracy: 0.0375 - val_loss: 3.4340\nEpoch 93/300\n\u001b[1m99/99\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 249ms/step - accuracy: 0.0299 - loss: 3.4340 - val_accuracy: 0.0375 - val_loss: 3.4340\nEpoch 94/300\n\u001b[1m99/99\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 249ms/step - accuracy: 0.0319 - loss: 3.4340 - val_accuracy: 0.0375 - val_loss: 3.4340\nEpoch 95/300\n\u001b[1m99/99\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 248ms/step - accuracy: 0.0318 - loss: 3.4340 - val_accuracy: 0.0375 - val_loss: 3.4340\nEpoch 96/300\n\u001b[1m99/99\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 248ms/step - accuracy: 0.0331 - loss: 3.4340 - val_accuracy: 0.0375 - val_loss: 3.4340\nEpoch 97/300\n\u001b[1m99/99\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 249ms/step - accuracy: 0.0306 - loss: 3.4340 - val_accuracy: 0.0375 - val_loss: 3.4340\nEpoch 98/300\n\u001b[1m99/99\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 249ms/step - accuracy: 0.0333 - loss: 3.4340 - val_accuracy: 0.0375 - val_loss: 3.4340\nEpoch 99/300\n\u001b[1m99/99\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 249ms/step - accuracy: 0.0358 - loss: 3.4340 - val_accuracy: 0.0375 - val_loss: 3.4340\nEpoch 100/300\n\u001b[1m99/99\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 249ms/step - accuracy: 0.0330 - loss: 3.4340 - val_accuracy: 0.0375 - val_loss: 3.4340\nEpoch 101/300\n\u001b[1m99/99\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 248ms/step - accuracy: 0.0305 - loss: 3.4340 - val_accuracy: 0.0375 - val_loss: 3.4340\nEpoch 102/300\n\u001b[1m99/99\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 249ms/step - accuracy: 0.0349 - loss: 3.4340 - val_accuracy: 0.0375 - val_loss: 3.4340\nEpoch 103/300\n\u001b[1m99/99\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 249ms/step - accuracy: 0.0291 - loss: 3.4340 - val_accuracy: 0.0375 - val_loss: 3.4340\nEpoch 104/300\n\u001b[1m99/99\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 249ms/step - accuracy: 0.0298 - loss: 3.4340 - val_accuracy: 0.0375 - val_loss: 3.4340\nEpoch 105/300\n\u001b[1m99/99\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 249ms/step - accuracy: 0.0301 - loss: 3.4340 - val_accuracy: 0.0375 - val_loss: 3.4340\nEpoch 106/300\n\u001b[1m99/99\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 249ms/step - accuracy: 0.0306 - loss: 3.4340 - val_accuracy: 0.0375 - val_loss: 3.4340\nEpoch 107/300\n\u001b[1m99/99\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 249ms/step - accuracy: 0.0292 - loss: 3.4340 - val_accuracy: 0.0375 - val_loss: 3.4340\nEpoch 108/300\n\u001b[1m99/99\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 249ms/step - accuracy: 0.0324 - loss: 3.4340 - val_accuracy: 0.0375 - val_loss: 3.4340\nEpoch 109/300\n\u001b[1m99/99\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 249ms/step - accuracy: 0.0366 - loss: 3.4340 - val_accuracy: 0.0375 - val_loss: 3.4340\nEpoch 110/300\n\u001b[1m99/99\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 249ms/step - accuracy: 0.0295 - loss: 3.4340 - val_accuracy: 0.0375 - val_loss: 3.4340\nEpoch 111/300\n\u001b[1m99/99\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 249ms/step - accuracy: 0.0292 - loss: 3.4340 - val_accuracy: 0.0375 - val_loss: 3.4340\nEpoch 112/300\n\u001b[1m99/99\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 249ms/step - accuracy: 0.0363 - loss: 3.4340 - val_accuracy: 0.0375 - val_loss: 3.4340\nEpoch 113/300\n\u001b[1m99/99\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 249ms/step - accuracy: 0.0354 - loss: 3.4340 - val_accuracy: 0.0375 - val_loss: 3.4340\nEpoch 114/300\n\u001b[1m99/99\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 249ms/step - accuracy: 0.0287 - loss: 3.4340 - val_accuracy: 0.0375 - val_loss: 3.4340\nEpoch 115/300\n\u001b[1m99/99\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 248ms/step - accuracy: 0.0291 - loss: 3.4340 - val_accuracy: 0.0375 - val_loss: 3.4340\nEpoch 116/300\n\u001b[1m99/99\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 248ms/step - accuracy: 0.0305 - loss: 3.4340 - val_accuracy: 0.0375 - val_loss: 3.4340\nEpoch 117/300\n\u001b[1m99/99\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 249ms/step - accuracy: 0.0309 - loss: 3.4340 - val_accuracy: 0.0375 - val_loss: 3.4340\nEpoch 118/300\n\u001b[1m99/99\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 249ms/step - accuracy: 0.0304 - loss: 3.4340 - val_accuracy: 0.0375 - val_loss: 3.4340\nEpoch 119/300\n\u001b[1m99/99\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 250ms/step - accuracy: 0.0335 - loss: 3.4340 - val_accuracy: 0.0375 - val_loss: 3.4340\nEpoch 120/300\n\u001b[1m99/99\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 249ms/step - accuracy: 0.0318 - loss: 3.4340 - val_accuracy: 0.0375 - val_loss: 3.4340\nEpoch 121/300\n\u001b[1m99/99\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 249ms/step - accuracy: 0.0327 - loss: 3.4340 - val_accuracy: 0.0375 - val_loss: 3.4340\nEpoch 122/300\n\u001b[1m99/99\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 249ms/step - accuracy: 0.0321 - loss: 3.4340 - val_accuracy: 0.0375 - val_loss: 3.4340\nEpoch 123/300\n\u001b[1m99/99\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 249ms/step - accuracy: 0.0381 - loss: 3.4340 - val_accuracy: 0.0375 - val_loss: 3.4340\nEpoch 124/300\n\u001b[1m99/99\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 249ms/step - accuracy: 0.0253 - loss: 3.4340 - val_accuracy: 0.0375 - val_loss: 3.4340\nEpoch 125/300\n\u001b[1m99/99\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 250ms/step - accuracy: 0.0354 - loss: 3.4340 - val_accuracy: 0.0375 - val_loss: 3.4340\nEpoch 126/300\n\u001b[1m99/99\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 248ms/step - accuracy: 0.0374 - loss: 3.4340 - val_accuracy: 0.0375 - val_loss: 3.4340\nEpoch 127/300\n\u001b[1m99/99\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 248ms/step - accuracy: 0.0307 - loss: 3.4340 - val_accuracy: 0.0375 - val_loss: 3.4340\nEpoch 128/300\n\u001b[1m99/99\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 250ms/step - accuracy: 0.0337 - loss: 3.4340 - val_accuracy: 0.0375 - val_loss: 3.4340\nEpoch 129/300\n\u001b[1m99/99\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 249ms/step - accuracy: 0.0286 - loss: 3.4340 - val_accuracy: 0.0375 - val_loss: 3.4340\nEpoch 130/300\n\u001b[1m99/99\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 249ms/step - accuracy: 0.0304 - loss: 3.4340 - val_accuracy: 0.0375 - val_loss: 3.4340\nEpoch 131/300\n\u001b[1m99/99\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 248ms/step - accuracy: 0.0361 - loss: 3.4340 - val_accuracy: 0.0375 - val_loss: 3.4340\nEpoch 132/300\n\u001b[1m99/99\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 249ms/step - accuracy: 0.0294 - loss: 3.4340 - val_accuracy: 0.0375 - val_loss: 3.4340\nEpoch 133/300\n\u001b[1m99/99\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 249ms/step - accuracy: 0.0299 - loss: 3.4340 - val_accuracy: 0.0375 - val_loss: 3.4340\nEpoch 134/300\n\u001b[1m99/99\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 249ms/step - accuracy: 0.0366 - loss: 3.4340 - val_accuracy: 0.0375 - val_loss: 3.4340\nEpoch 135/300\n\u001b[1m99/99\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 249ms/step - accuracy: 0.0341 - loss: 3.4340 - val_accuracy: 0.0375 - val_loss: 3.4340\nEpoch 136/300\n\u001b[1m99/99\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 249ms/step - accuracy: 0.0343 - loss: 3.4340 - val_accuracy: 0.0375 - val_loss: 3.4340\nEpoch 137/300\n\u001b[1m99/99\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 249ms/step - accuracy: 0.0346 - loss: 3.4340 - val_accuracy: 0.0375 - val_loss: 3.4340\nEpoch 138/300\n\u001b[1m99/99\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 248ms/step - accuracy: 0.0300 - loss: 3.4340 - val_accuracy: 0.0375 - val_loss: 3.4340\nEpoch 139/300\n\u001b[1m99/99\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 249ms/step - accuracy: 0.0289 - loss: 3.4340 - val_accuracy: 0.0375 - val_loss: 3.4340\nEpoch 140/300\n\u001b[1m99/99\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 249ms/step - accuracy: 0.0371 - loss: 3.4340 - val_accuracy: 0.0375 - val_loss: 3.4340\nEpoch 141/300\n\u001b[1m99/99\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 248ms/step - accuracy: 0.0337 - loss: 3.4340 - val_accuracy: 0.0375 - val_loss: 3.4340\nEpoch 142/300\n\u001b[1m99/99\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 249ms/step - accuracy: 0.0367 - loss: 3.4340 - val_accuracy: 0.0375 - val_loss: 3.4340\nEpoch 143/300\n\u001b[1m99/99\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 249ms/step - accuracy: 0.0324 - loss: 3.4340 - val_accuracy: 0.0375 - val_loss: 3.4340\nEpoch 144/300\n\u001b[1m99/99\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 249ms/step - accuracy: 0.0311 - loss: 3.4340 - val_accuracy: 0.0375 - val_loss: 3.4340\nEpoch 145/300\n\u001b[1m99/99\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 249ms/step - accuracy: 0.0355 - loss: 3.4340 - val_accuracy: 0.0375 - val_loss: 3.4340\nEpoch 146/300\n\u001b[1m99/99\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 249ms/step - accuracy: 0.0340 - loss: 3.4340 - val_accuracy: 0.0375 - val_loss: 3.4340\nEpoch 147/300\n\u001b[1m99/99\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 249ms/step - accuracy: 0.0260 - loss: 3.4340 - val_accuracy: 0.0375 - val_loss: 3.4340\nEpoch 148/300\n\u001b[1m99/99\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 249ms/step - accuracy: 0.0310 - loss: 3.4340 - val_accuracy: 0.0375 - val_loss: 3.4340\nEpoch 149/300\n\u001b[1m99/99\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 249ms/step - accuracy: 0.0292 - loss: 3.4340 - val_accuracy: 0.0375 - val_loss: 3.4340\nEpoch 150/300\n\u001b[1m99/99\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 248ms/step - accuracy: 0.0354 - loss: 3.4340 - val_accuracy: 0.0375 - val_loss: 3.4340\nEpoch 151/300\n\u001b[1m99/99\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 249ms/step - accuracy: 0.0343 - loss: 3.4340 - val_accuracy: 0.0375 - val_loss: 3.4340\nEpoch 152/300\n\u001b[1m99/99\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 249ms/step - accuracy: 0.0332 - loss: 3.4340 - val_accuracy: 0.0375 - val_loss: 3.4340\nEpoch 153/300\n\u001b[1m99/99\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 249ms/step - accuracy: 0.0319 - loss: 3.4340 - val_accuracy: 0.0375 - val_loss: 3.4340\nEpoch 154/300\n\u001b[1m99/99\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 249ms/step - accuracy: 0.0342 - loss: 3.4340 - val_accuracy: 0.0375 - val_loss: 3.4340\nEpoch 155/300\n\u001b[1m62/99\u001b[0m \u001b[32m━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━\u001b[0m \u001b[1m8s\u001b[0m 233ms/step - accuracy: 0.0297 - loss: 3.4340","output_type":"stream"},{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m/tmp/ipykernel_5901/537410411.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     21\u001b[0m     \u001b[0mmetrics\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'accuracy'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m )\n\u001b[0;32m---> 23\u001b[0;31m history_eff = eff_model.fit(    X_train,\n\u001b[0m\u001b[1;32m     24\u001b[0m     \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m     \u001b[0mvalidation_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/keras/src/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    115\u001b[0m         \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    116\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 117\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    118\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    119\u001b[0m             \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/keras/src/backend/tensorflow/trainer.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq)\u001b[0m\n\u001b[1;32m    318\u001b[0m                 \u001b[0;32mfor\u001b[0m \u001b[0mstep\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0miterator\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mepoch_iterator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menumerate_epoch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    319\u001b[0m                     \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 320\u001b[0;31m                     \u001b[0mlogs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    321\u001b[0m                     \u001b[0mlogs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_pythonify_logs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlogs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    322\u001b[0m                     \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_batch_end\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/tensorflow/python/util/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    148\u001b[0m     \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    149\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 150\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    151\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    152\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    831\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    832\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0mOptionalXlaContext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jit_compile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 833\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    834\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    835\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    876\u001b[0m       \u001b[0;31m# In this case we have not created variables on the first call. So we can\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    877\u001b[0m       \u001b[0;31m# run the first trace but we should fail if variables are created.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 878\u001b[0;31m       results = tracing_compilation.call_function(\n\u001b[0m\u001b[1;32m    879\u001b[0m           \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_variable_creation_config\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    880\u001b[0m       )\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/tensorflow/python/eager/polymorphic_function/tracing_compilation.py\u001b[0m in \u001b[0;36mcall_function\u001b[0;34m(args, kwargs, tracing_options)\u001b[0m\n\u001b[1;32m    137\u001b[0m   \u001b[0mbound_args\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunction\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunction_type\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbind\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    138\u001b[0m   \u001b[0mflat_inputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunction\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunction_type\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munpack_inputs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbound_args\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 139\u001b[0;31m   return function._call_flat(  # pylint: disable=protected-access\n\u001b[0m\u001b[1;32m    140\u001b[0m       \u001b[0mflat_inputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcaptured_inputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfunction\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcaptured_inputs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    141\u001b[0m   )\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/tensorflow/python/eager/polymorphic_function/concrete_function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, tensor_inputs, captured_inputs)\u001b[0m\n\u001b[1;32m   1320\u001b[0m         and executing_eagerly):\n\u001b[1;32m   1321\u001b[0m       \u001b[0;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1322\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_inference_function\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcall_preflattened\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1323\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n\u001b[1;32m   1324\u001b[0m         \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/tensorflow/python/eager/polymorphic_function/atomic_function.py\u001b[0m in \u001b[0;36mcall_preflattened\u001b[0;34m(self, args)\u001b[0m\n\u001b[1;32m    214\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mcall_preflattened\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mSequence\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mAny\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    215\u001b[0m     \u001b[0;34m\"\"\"Calls with flattened tensor inputs and returns the structured output.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 216\u001b[0;31m     \u001b[0mflat_outputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcall_flat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    217\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunction_type\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpack_output\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mflat_outputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    218\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/tensorflow/python/eager/polymorphic_function/atomic_function.py\u001b[0m in \u001b[0;36mcall_flat\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m    249\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mrecord\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstop_recording\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    250\u001b[0m           \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_bound_context\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexecuting_eagerly\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 251\u001b[0;31m             outputs = self._bound_context.call_function(\n\u001b[0m\u001b[1;32m    252\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    253\u001b[0m                 \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/tensorflow/python/eager/context.py\u001b[0m in \u001b[0;36mcall_function\u001b[0;34m(self, name, tensor_inputs, num_outputs)\u001b[0m\n\u001b[1;32m   1681\u001b[0m     \u001b[0mcancellation_context\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcancellation\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1682\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mcancellation_context\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1683\u001b[0;31m       outputs = execute.execute(\n\u001b[0m\u001b[1;32m   1684\u001b[0m           \u001b[0mname\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"utf-8\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1685\u001b[0m           \u001b[0mnum_outputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnum_outputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     51\u001b[0m   \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     52\u001b[0m     \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 53\u001b[0;31m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0m\u001b[1;32m     54\u001b[0m                                         inputs, attrs, num_outputs)\n\u001b[1;32m     55\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "],"ename":"KeyboardInterrupt","evalue":"","output_type":"error"}],"execution_count":18},{"cell_type":"code","source":"from PIL import Image, ImageFile\nImageFile.LOAD_TRUNCATED_IMAGES = True\ndef remove_corrupt_images(directory):\n    invalid = []\n    for root, _, files in os.walk(directory):\n        for f in files:\n            if f.lower().endswith('.jpg') or f.lower().endswith('.jpeg'):\n                path = os.path.join(root, f)\n                try:\n                    with Image.open(path) as img:\n                        img.verify()\n                except Exception as e:\n                    invalid.append(path)\n    return invalid\n\ninvalid = remove_corrupt_images(\"/kaggle/input/rgb-arabic-alphabets-sign-language-dataset/RGB ArSL dataset\")","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"len(invalid)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import os\nimport cv2\nimport torch\nfrom torch.utils.data import Dataset\nfrom transformers import AutoImageProcessor\n\nprocessor = AutoImageProcessor.from_pretrained(\"google/siglip-base-patch16-224\",use_fast = True)\n\nclass ArSLDataset(Dataset):\n    def __init__(self, root_dir, processor):\n        self.samples = []\n        self.labels_map = {}\n        self.processor = processor\n\n        label_id = 0\n        for dirname, _, filenames in os.walk(root_dir):\n            label = os.path.basename(dirname)\n            if not filenames or label.startswith(\".\"):\n                continue  # skip hidden or empty folders\n            if label not in self.labels_map:\n                self.labels_map[label] = label_id\n                label_id += 1\n            for filename in filenames:\n                filepath = os.path.join(dirname, filename)\n                self.samples.append((filepath, self.labels_map[label]))\n\n    def __len__(self):\n        return len(self.samples)\n\n    def __getitem__(self, idx):\n        img_path, label = self.samples[idx]\n        try:\n            # Use cv2 to read the image (convert to RGB)\n            image = cv2.imread(img_path)\n            image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n        except:\n            print(f\"Failed to load image: {img_path}\")\n            image = 255 * np.ones((224, 224, 3), dtype=np.uint8)  # fallback: white image\n\n        encoding = self.processor(images=image, return_tensors=\"pt\")\n        return {\n            \"pixel_values\": encoding[\"pixel_values\"].squeeze(0),\n            \"labels\": torch.tensor(label, dtype=torch.long)\n        }\n\n\nroot = \"/kaggle/input/rgb-arabic-alphabets-sign-language-dataset/RGB ArSL dataset\"\ndataset = ArSLDataset(root, processor)\n\n\nfrom torch.utils.data import random_split\n\n\ntrain_size = int(0.8 * len(dataset))\nval_size = len(dataset) - train_size\ntrain_dataset, val_dataset = random_split(dataset, [train_size, val_size])\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-09T11:15:46.548213Z","iopub.execute_input":"2025-05-09T11:15:46.548418Z","iopub.status.idle":"2025-05-09T11:16:28.566021Z","shell.execute_reply.started":"2025-05-09T11:15:46.548402Z","shell.execute_reply":"2025-05-09T11:16:28.565184Z"}},"outputs":[{"name":"stderr","text":"2025-05-09 11:15:59.028771: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\nWARNING: All log messages before absl::InitializeLog() is called are written to STDERR\nE0000 00:00:1746789359.263555      31 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\nE0000 00:00:1746789359.344609      31 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"preprocessor_config.json:   0%|          | 0.00/368 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"26368dbe9c7f443092bd3c3674d478bf"}},"metadata":{}}],"execution_count":1},{"cell_type":"code","source":"from transformers import AutoImageProcessor, ResNetForImageClassification\n\nprocessor = AutoImageProcessor.from_pretrained(\"microsoft/resnet-50\")\n\nres_model = ResNetForImageClassification.from_pretrained(\n    \"microsoft/resnet-50\",\n    num_labels=31,ignore_mismatched_sizes=True\n)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-09T11:16:28.569701Z","iopub.execute_input":"2025-05-09T11:16:28.569882Z","iopub.status.idle":"2025-05-09T11:16:31.006691Z","shell.execute_reply.started":"2025-05-09T11:16:28.569865Z","shell.execute_reply":"2025-05-09T11:16:31.006113Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"preprocessor_config.json:   0%|          | 0.00/266 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"e9f33478aaea418b872e811401b72ef2"}},"metadata":{}},{"name":"stderr","text":"Using a slow image processor as `use_fast` is unset and a slow processor was saved with this model. `use_fast=True` will be the default behavior in v4.52, even if the model was saved with a slow processor. This will result in minor differences in outputs. You'll still be able to use a slow processor with `use_fast=False`.\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"config.json:   0%|          | 0.00/69.6k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"bc216878342140508811b2845db4df40"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"model.safetensors:   0%|          | 0.00/102M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"15a4e762481c46a08d6a3b858c691e5c"}},"metadata":{}},{"name":"stderr","text":"Some weights of ResNetForImageClassification were not initialized from the model checkpoint at microsoft/resnet-50 and are newly initialized because the shapes did not match:\n- classifier.1.bias: found shape torch.Size([1000]) in the checkpoint and torch.Size([31]) in the model instantiated\n- classifier.1.weight: found shape torch.Size([1000, 2048]) in the checkpoint and torch.Size([31, 2048]) in the model instantiated\nYou should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","output_type":"stream"}],"execution_count":2},{"cell_type":"code","source":"from transformers import TrainingArguments\nfrom transformers import DefaultDataCollator\nfrom sklearn.metrics import accuracy_score\ndata_collator = DefaultDataCollator()\n\ndef compute_metrics(eval_pred):\n    logits, labels = eval_pred\n    preds = logits.argmax(-1)\n    acc = accuracy_score(labels, preds)\n    return {\"accuracy\": acc}\n    \ntraining_args = TrainingArguments(\n    output_dir=\"./results_resnet\",\n    per_device_train_batch_size=32,\n    per_device_eval_batch_size=32,\n    num_train_epochs=5,\n     weight_decay=0.01,\n    eval_strategy =\"epoch\",\n    save_strategy=\"epoch\",\n    logging_strategy=\"epoch\",\n    report_to=\"none\",  \n    load_best_model_at_end=True,\n    dataloader_num_workers=4,   \n    dataloader_pin_memory=True\n)\n    \nfrom transformers import Trainer\n\ntrainer = Trainer(\n    model=res_model,\n    args=training_args,\n    train_dataset=train_dataset,\n    eval_dataset=val_dataset,\n    data_collator=data_collator,\n    processing_class = processor,\n    compute_metrics=compute_metrics\n)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-09T11:37:20.224357Z","iopub.execute_input":"2025-05-09T11:37:20.224652Z","iopub.status.idle":"2025-05-09T11:37:20.268840Z","shell.execute_reply.started":"2025-05-09T11:37:20.224630Z","shell.execute_reply":"2025-05-09T11:37:20.268325Z"}},"outputs":[],"execution_count":16},{"cell_type":"code","source":"trainer.train()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-09T11:37:23.786312Z","iopub.execute_input":"2025-05-09T11:37:23.786580Z","iopub.status.idle":"2025-05-09T12:18:37.681105Z","shell.execute_reply.started":"2025-05-09T11:37:23.786560Z","shell.execute_reply":"2025-05-09T12:18:37.680190Z"}},"outputs":[{"name":"stderr","text":"/usr/local/lib/python3.11/dist-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn(\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n    <div>\n      \n      <progress value='495' max='495' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [495/495 40:56, Epoch 5/5]\n    </div>\n    <table border=\"1\" class=\"dataframe\">\n  <thead>\n <tr style=\"text-align: left;\">\n      <th>Epoch</th>\n      <th>Training Loss</th>\n      <th>Validation Loss</th>\n      <th>Accuracy</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <td>1</td>\n      <td>3.325900</td>\n      <td>3.292609</td>\n      <td>0.154580</td>\n    </tr>\n    <tr>\n      <td>2</td>\n      <td>3.163600</td>\n      <td>3.030396</td>\n      <td>0.306616</td>\n    </tr>\n    <tr>\n      <td>3</td>\n      <td>2.883400</td>\n      <td>2.719919</td>\n      <td>0.468193</td>\n    </tr>\n    <tr>\n      <td>4</td>\n      <td>2.625900</td>\n      <td>2.525049</td>\n      <td>0.564249</td>\n    </tr>\n    <tr>\n      <td>5</td>\n      <td>2.478000</td>\n      <td>2.445314</td>\n      <td>0.575064</td>\n    </tr>\n  </tbody>\n</table><p>"},"metadata":{}},{"name":"stderr","text":"Premature end of JPEG file\n/usr/local/lib/python3.11/dist-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn(\nPremature end of JPEG file\n/usr/local/lib/python3.11/dist-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn(\nPremature end of JPEG file\n/usr/local/lib/python3.11/dist-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn(\nPremature end of JPEG file\n/usr/local/lib/python3.11/dist-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn(\nPremature end of JPEG file\n","output_type":"stream"},{"execution_count":17,"output_type":"execute_result","data":{"text/plain":"TrainOutput(global_step=495, training_loss=2.8953519878965435, metrics={'train_runtime': 2473.2591, 'train_samples_per_second': 12.704, 'train_steps_per_second': 0.2, 'total_flos': 6.689025974215066e+17, 'train_loss': 2.8953519878965435, 'epoch': 5.0})"},"metadata":{}}],"execution_count":17},{"cell_type":"code","source":"trainer.train()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-09T12:19:58.632379Z","iopub.execute_input":"2025-05-09T12:19:58.633232Z","iopub.status.idle":"2025-05-09T13:00:28.115682Z","shell.execute_reply.started":"2025-05-09T12:19:58.633200Z","shell.execute_reply":"2025-05-09T13:00:28.114933Z"}},"outputs":[{"name":"stderr","text":"/usr/local/lib/python3.11/dist-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn(\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n    <div>\n      \n      <progress value='495' max='495' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [495/495 40:11, Epoch 5/5]\n    </div>\n    <table border=\"1\" class=\"dataframe\">\n  <thead>\n <tr style=\"text-align: left;\">\n      <th>Epoch</th>\n      <th>Training Loss</th>\n      <th>Validation Loss</th>\n      <th>Accuracy</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <td>1</td>\n      <td>2.121600</td>\n      <td>1.722301</td>\n      <td>0.700382</td>\n    </tr>\n    <tr>\n      <td>2</td>\n      <td>1.527100</td>\n      <td>1.217066</td>\n      <td>0.795802</td>\n    </tr>\n    <tr>\n      <td>3</td>\n      <td>1.157600</td>\n      <td>0.960307</td>\n      <td>0.842239</td>\n    </tr>\n    <tr>\n      <td>4</td>\n      <td>0.950900</td>\n      <td>0.846429</td>\n      <td>0.865776</td>\n    </tr>\n    <tr>\n      <td>5</td>\n      <td>0.858300</td>\n      <td>0.805682</td>\n      <td>0.869593</td>\n    </tr>\n  </tbody>\n</table><p>"},"metadata":{}},{"name":"stderr","text":"Premature end of JPEG file\n/usr/local/lib/python3.11/dist-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn(\nPremature end of JPEG file\n/usr/local/lib/python3.11/dist-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn(\nPremature end of JPEG file\n/usr/local/lib/python3.11/dist-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn(\nPremature end of JPEG file\n/usr/local/lib/python3.11/dist-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn(\nPremature end of JPEG file\n","output_type":"stream"},{"execution_count":18,"output_type":"execute_result","data":{"text/plain":"TrainOutput(global_step=495, training_loss=1.323099849200008, metrics={'train_runtime': 2428.8186, 'train_samples_per_second': 12.936, 'train_steps_per_second': 0.204, 'total_flos': 6.689025974215066e+17, 'train_loss': 1.323099849200008, 'epoch': 5.0})"},"metadata":{}}],"execution_count":18},{"cell_type":"code","source":"trainer.train()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-09T13:01:03.933882Z","iopub.execute_input":"2025-05-09T13:01:03.934237Z","iopub.status.idle":"2025-05-09T13:42:50.334310Z","shell.execute_reply.started":"2025-05-09T13:01:03.934208Z","shell.execute_reply":"2025-05-09T13:42:50.333458Z"}},"outputs":[{"name":"stderr","text":"/usr/local/lib/python3.11/dist-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn(\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n    <div>\n      \n      <progress value='495' max='495' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [495/495 41:28, Epoch 5/5]\n    </div>\n    <table border=\"1\" class=\"dataframe\">\n  <thead>\n <tr style=\"text-align: left;\">\n      <th>Epoch</th>\n      <th>Training Loss</th>\n      <th>Validation Loss</th>\n      <th>Accuracy</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <td>1</td>\n      <td>0.704200</td>\n      <td>0.541735</td>\n      <td>0.913486</td>\n    </tr>\n    <tr>\n      <td>2</td>\n      <td>0.488400</td>\n      <td>0.410288</td>\n      <td>0.925573</td>\n    </tr>\n    <tr>\n      <td>3</td>\n      <td>0.382100</td>\n      <td>0.341616</td>\n      <td>0.928117</td>\n    </tr>\n    <tr>\n      <td>4</td>\n      <td>0.314100</td>\n      <td>0.317125</td>\n      <td>0.936387</td>\n    </tr>\n    <tr>\n      <td>5</td>\n      <td>0.285700</td>\n      <td>0.297231</td>\n      <td>0.940204</td>\n    </tr>\n  </tbody>\n</table><p>"},"metadata":{}},{"name":"stderr","text":"Premature end of JPEG file\n/usr/local/lib/python3.11/dist-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn(\nPremature end of JPEG file\n/usr/local/lib/python3.11/dist-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn(\nPremature end of JPEG file\n/usr/local/lib/python3.11/dist-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn(\nPremature end of JPEG file\n/usr/local/lib/python3.11/dist-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn(\nPremature end of JPEG file\n","output_type":"stream"},{"execution_count":19,"output_type":"execute_result","data":{"text/plain":"TrainOutput(global_step=495, training_loss=0.43491293011289656, metrics={'train_runtime': 2505.7328, 'train_samples_per_second': 12.539, 'train_steps_per_second': 0.198, 'total_flos': 6.689025974215066e+17, 'train_loss': 0.43491293011289656, 'epoch': 5.0})"},"metadata":{}}],"execution_count":19},{"cell_type":"code","source":"metrics = trainer.evaluate()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-09T13:43:35.241783Z","iopub.execute_input":"2025-05-09T13:43:35.242495Z","iopub.status.idle":"2025-05-09T13:45:07.970457Z","shell.execute_reply.started":"2025-05-09T13:43:35.242469Z","shell.execute_reply":"2025-05-09T13:45:07.969715Z"}},"outputs":[{"name":"stderr","text":"Premature end of JPEG file\n/usr/local/lib/python3.11/dist-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn(\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n    <div>\n      \n      <progress value='25' max='25' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [25/25 01:14]\n    </div>\n    "},"metadata":{}}],"execution_count":22},{"cell_type":"code","source":"metrics","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-09T13:45:07.971793Z","iopub.execute_input":"2025-05-09T13:45:07.972020Z","iopub.status.idle":"2025-05-09T13:45:07.977378Z","shell.execute_reply.started":"2025-05-09T13:45:07.971999Z","shell.execute_reply":"2025-05-09T13:45:07.976785Z"}},"outputs":[{"execution_count":23,"output_type":"execute_result","data":{"text/plain":"{'eval_loss': 0.29723137617111206,\n 'eval_accuracy': 0.9402035623409669,\n 'eval_runtime': 92.7216,\n 'eval_samples_per_second': 16.954,\n 'eval_steps_per_second': 0.27,\n 'epoch': 5.0}"},"metadata":{}}],"execution_count":23},{"cell_type":"code","source":"trainer.save_model(\"resnet50-final model\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-09T13:45:15.536000Z","iopub.execute_input":"2025-05-09T13:45:15.536579Z","iopub.status.idle":"2025-05-09T13:45:15.702144Z","shell.execute_reply.started":"2025-05-09T13:45:15.536557Z","shell.execute_reply":"2025-05-09T13:45:15.701575Z"}},"outputs":[],"execution_count":24},{"cell_type":"code","source":"import shutil\n\n# Define source folder and output zip path (no need to add .zip to output name)\nsource_folder = '/kaggle/working/resnet50-final model'\noutput_zip = '/kaggle/working/resnet50-94'  # This will create output.zip\n\n# Create the zip archive\nshutil.make_archive(output_zip, 'zip', source_folder)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-09T13:46:13.755164Z","iopub.execute_input":"2025-05-09T13:46:13.755619Z","iopub.status.idle":"2025-05-09T13:46:18.326290Z","shell.execute_reply.started":"2025-05-09T13:46:13.755598Z","shell.execute_reply":"2025-05-09T13:46:18.325685Z"}},"outputs":[{"execution_count":25,"output_type":"execute_result","data":{"text/plain":"'/kaggle/working/resnet50-94.zip'"},"metadata":{}}],"execution_count":25},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}